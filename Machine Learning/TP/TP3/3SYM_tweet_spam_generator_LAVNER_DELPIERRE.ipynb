{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP3_LAVNER_DELPIERRE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQw0YnIvwpuX",
        "colab_type": "text"
      },
      "source": [
        "**Tweet spam generator**\n",
        "\n",
        "Our goal is to code a bot that can output realistic tweets. For that purpose, we are given a dataset of 100k tweets. The first part will be to train an encoder/decoder that we can use as a generator. The second part will be to train our generator using an adversarial critic that distinguish between real tweets and generated tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eunaytrspnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sulMBxxSoBGz",
        "colab_type": "code",
        "outputId": "16615f4a-8560-4a77-9b01-6371bcae26db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!wget http://perso-etis.ensea.fr/picard/tweets_100k.txt;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-05 09:46:43--  http://perso-etis.ensea.fr/picard/tweets_100k.txt\n",
            "Resolving perso-etis.ensea.fr (perso-etis.ensea.fr)... 193.51.45.246\n",
            "Connecting to perso-etis.ensea.fr (perso-etis.ensea.fr)|193.51.45.246|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://perso-etis.ensea.fr//picard/tweets_100k.txt [following]\n",
            "--2019-06-05 09:46:44--  https://perso-etis.ensea.fr//picard/tweets_100k.txt\n",
            "Connecting to perso-etis.ensea.fr (perso-etis.ensea.fr)|193.51.45.246|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6267498 (6.0M) [text/plain]\n",
            "Saving to: ‘tweets_100k.txt.1’\n",
            "\n",
            "tweets_100k.txt.1   100%[===================>]   5.98M  6.64MB/s    in 0.9s    \n",
            "\n",
            "2019-06-05 09:46:45 (6.64 MB/s) - ‘tweets_100k.txt.1’ saved [6267498/6267498]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOTpuBj1t2kf",
        "colab_type": "text"
      },
      "source": [
        "**Prepare dataset**\n",
        "\n",
        "convert string to sequences of integer and pad right with zeros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSGQyedWoIjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = []\n",
        "with open('tweets_100k.txt', 'r') as f:\n",
        "  for line in f:\n",
        "    tweets.append(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7ibiR8y4Lb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Générateur de phrases en anglais\n",
        "# Copié et adapté depuis http://pythonfiddle.com/random-sentence-generator/\n",
        "import random\n",
        "\n",
        "s_nouns = [\"A dude\", \"My mom\", \"The king\", \"Some guy\", \"A cat with rabies\", \"A sloth\", \"Your homie\", \"This cool guy my gardener met yesterday\", \"Superman\"]\n",
        "p_nouns = [\"These dudes\", \"Both of my moms\", \"All the kings of the world\", \"Some guys\", \"All of a cattery's cats\", \"The multitude of sloths living under your bed\", \"Your homies\", \"Like, these, like, all these people\", \"Supermen\"]\n",
        "s_verbs = [\"eats\", \"kicks\", \"gives\", \"treats\", \"meets with\", \"creates\", \"hacks\", \"configures\", \"spies on\", \"retards\", \"meows on\", \"flees from\", \"tries to automate\", \"explodes\"]\n",
        "p_verbs = [\"eat\", \"kick\", \"give\", \"treat\", \"meet with\", \"create\", \"hack\", \"configure\", \"spy on\", \"retard\", \"meow on\", \"flee from\", \"try to automate\", \"explode\"]\n",
        "infinitives = [\"to make a pie \\n\", \"for no apparent reason \\n\", \"because the sky is green \\n\", \"for a disease \\n\", \"to be able to make toast explode \\n\", \"to know more about archeology \\n\"]\n",
        "def gen():\n",
        "  return ' '.join((random.choice(s_nouns), random.choice(s_verbs), random.choice(p_nouns).lower(), random.choice(infinitives)))\n",
        "\n",
        "def gen_n(n):\n",
        "  tweets_test = []\n",
        "  for i in range(n):\n",
        "    tweets_test.append(gen())\n",
        "  return tweets_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiPLvztDrGuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tweet_encoder(tweets):\n",
        "  x = []\n",
        "  for t in tweets:\n",
        "    x.append([ord(c) for c in t])\n",
        "  x = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=140, padding='post', value=0)\n",
        "  return np.array(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOZGCbqc6yZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = tweet_encoder(tweets)\n",
        "\n",
        "X_test =  tweet_encoder(gen_n(100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5gH_VapuBUC",
        "colab_type": "text"
      },
      "source": [
        "**Create batch generator**\n",
        "\n",
        "Converting the list of integers to one-hot vectors would exhaust the memory. The generator allows us to generate the large sparse vectors on the fly, only when needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4w9CMqcps58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TweetSequence(tf.keras.utils.Sequence):\n",
        "  def __init__(self, x, batch_size=32):\n",
        "    self.x = x\n",
        "    self.batch_size = batch_size\n",
        "  def __len__(self):\n",
        "    return len(self.x)//self.batch_size\n",
        "  def __getitem__(self, idx):\n",
        "    batch = self.x[idx*self.batch_size:(idx+1)*self.batch_size, :]\n",
        "    batch = tf.keras.utils.to_categorical(batch, num_classes=256)\n",
        "    return batch, batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRnAHQewwE5H",
        "colab_type": "text"
      },
      "source": [
        "**Create autoencoder model**\n",
        "\n",
        "Create a deep neural network that encodes and decodes the character string. The objective is to perform reconstruction, that is, recovering the same one hot sequence as the input at the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGcJSd-KTBSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = TweetSequence(X_train)\n",
        "X_test = TweetSequence(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCr1IGIX8Wgi",
        "colab_type": "text"
      },
      "source": [
        "## Test avec layer Dense fully connected\n",
        "Cela implique trop de paramètres, et en tenant compte de la présence de LSTM, l'entraînement est trop long.\n",
        "On testera par la suite un autre modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltODCHIetqr-",
        "colab_type": "code",
        "outputId": "aa7a32c5-2537-4593-ae0a-5f61de95df11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "timesteps = 140\n",
        "input_dim = 256\n",
        "\n",
        "encoder_inputs = Input(shape=(timesteps, input_dim))\n",
        "encoder_lstm = CuDNNLSTM(input_dim)(encoder_inputs)\n",
        "\n",
        "decoder_inputs = Input(shape=(input_dim,))\n",
        "decoder_dense = Dense(timesteps*input_dim)(decoder_inputs)\n",
        "decoder_reshape = Reshape((timesteps, input_dim))(decoder_dense)\n",
        "decoder_lstm = CuDNNLSTM(input_dim, return_sequences=True)(decoder_reshape)\n",
        "decoder_outputs = Activation('softmax')(decoder_reshape)\n",
        "\n",
        "encoder = Model(inputs=encoder_inputs, outputs=encoder_lstm)\n",
        "decoder = Model(inputs=decoder_inputs, outputs=decoder_outputs)\n",
        "\n",
        "encoder.summary()\n",
        "decoder.summary()\n",
        "\n",
        "sequence_autoencoder = Sequential()\n",
        "sequence_autoencoder.add(encoder)\n",
        "sequence_autoencoder.add(decoder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 140, 256)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm (CuDNNLSTM)       (None, 256)               526336    \n",
            "=================================================================\n",
            "Total params: 526,336\n",
            "Trainable params: 526,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 35840)             9210880   \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 140, 256)          0         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 140, 256)          0         \n",
            "=================================================================\n",
            "Total params: 9,210,880\n",
            "Trainable params: 9,210,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lCueFNdR6FC",
        "colab_type": "code",
        "outputId": "ae768087-8a31-4f1f-d7b8-cc83ecc4e105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "sequence_autoencoder.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "sequence_autoencoder.fit_generator(x_seq, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3125/3125 [==============================] - 286s 92ms/step - loss: 3.9043\n",
            "Epoch 2/5\n",
            "3125/3125 [==============================] - 279s 89ms/step - loss: 3.8550\n",
            "Epoch 3/5\n",
            "3125/3125 [==============================] - 280s 90ms/step - loss: 3.8536\n",
            "Epoch 4/5\n",
            " 484/3125 [===>..........................] - ETA: 3:55 - loss: 3.8547"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-98de2b46f0e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msequence_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msequence_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 176\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb2Xkytq9FIY",
        "colab_type": "code",
        "outputId": "36ed32f8-1edf-494d-9332-e79b2e5a925d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "timesteps = 140\n",
        "input_dim = 256\n",
        "\n",
        "encoder_inputs = Input(shape=(timesteps, input_dim))\n",
        "x = Conv1D(32, 3, activation='relu', padding='same')(encoder_inputs)\n",
        "x = MaxPooling1D(2, padding='same')(x)\n",
        "x = Conv1D(16, 3, activation='relu', padding='same')(x)\n",
        "x = MaxPooling1D(2, padding='same')(x)\n",
        "x = Conv1D(8, 3, activation='relu', padding='same')(x)\n",
        "encoded = Flatten()(x)\n",
        "\n",
        "decoder_inputs = Input(shape=(280,))\n",
        "x = Reshape((35,8))(decoder_inputs)\n",
        "x = Conv1D(32, 3, activation='relu', padding='same')(x)\n",
        "x = UpSampling1D(2)(x)\n",
        "x = Conv1D(64, 3, activation='relu', padding='same')(x)\n",
        "x = UpSampling1D(2)(x)\n",
        "decoded = Conv1D(256, 3, activation='softmax', padding='same')(x)\n",
        "\n",
        "encoder = Model(inputs=encoder_inputs, outputs=encoded)\n",
        "decoder = Model(inputs=decoder_inputs, outputs=decoded)\n",
        "\n",
        "encoder.summary()\n",
        "decoder.summary()\n",
        "\n",
        "sequence_autoencoder = Sequential()\n",
        "sequence_autoencoder.add(encoder)\n",
        "sequence_autoencoder.add(decoder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 140, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 140, 32)           24608     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 70, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 70, 16)            1552      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 35, 16)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 35, 8)             392       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 280)               0         \n",
            "=================================================================\n",
            "Total params: 26,552\n",
            "Trainable params: 26,552\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 280)               0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 35, 8)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 35, 32)            800       \n",
            "_________________________________________________________________\n",
            "up_sampling1d (UpSampling1D) (None, 70, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 70, 64)            6208      \n",
            "_________________________________________________________________\n",
            "up_sampling1d_1 (UpSampling1 (None, 140, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 140, 256)          49408     \n",
            "=================================================================\n",
            "Total params: 56,416\n",
            "Trainable params: 56,416\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yGRmeANTVkD",
        "colab_type": "code",
        "outputId": "fa19ab22-4dd2-4c6a-e46c-4de821691781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "source": [
        "sequence_autoencoder.compile(optimizer='adadelta', loss='categorical_crossentropy')\n",
        "sequence_autoencoder.fit_generator(x_seq, epochs=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 1.1008\n",
            "Epoch 2/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8385\n",
            "Epoch 3/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.7461\n",
            "Epoch 4/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.6453\n",
            "Epoch 5/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.5681\n",
            "Epoch 6/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.5312\n",
            "Epoch 7/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.5042\n",
            "Epoch 8/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.4831\n",
            "Epoch 9/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.4673\n",
            "Epoch 10/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.4544\n",
            "Epoch 11/30\n",
            "3125/3125 [==============================] - 61s 20ms/step - loss: 0.4443\n",
            "Epoch 12/30\n",
            "3125/3125 [==============================] - 61s 20ms/step - loss: 0.4364\n",
            "Epoch 13/30\n",
            "3125/3125 [==============================] - 61s 20ms/step - loss: 0.4295\n",
            "Epoch 14/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.4233\n",
            "Epoch 15/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.4181\n",
            "Epoch 16/30\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.4134\n",
            "Epoch 17/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.4090\n",
            "Epoch 18/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.4057\n",
            "Epoch 19/30\n",
            "3125/3125 [==============================] - 64s 21ms/step - loss: 0.4017\n",
            "Epoch 20/30\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.3979\n",
            "Epoch 21/30\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.3940\n",
            "Epoch 22/30\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.3914\n",
            "Epoch 23/30\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.3881\n",
            "Epoch 24/30\n",
            "3125/3125 [==============================] - 64s 21ms/step - loss: 0.3847\n",
            "Epoch 25/30\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.3820\n",
            "Epoch 26/30\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.3789\n",
            "Epoch 27/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.3770\n",
            "Epoch 28/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.3746\n",
            "Epoch 29/30\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.3724\n",
            "Epoch 30/30\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.3704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffb61044dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o323et_osK5x",
        "colab_type": "text"
      },
      "source": [
        "Le score de loss paraît bon (on pourrait mettre plus d'epochs pour l'améliorer), on va maintenant tester le modèle sur un tweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjceAxed_oZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_autoencoder.save('auto1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDCn3D7tmzaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "sequence_autoencoder = load_model('auto1.h5') # pour éviter de devoir réentraîner le model tous les jours"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OSTgqBm_gQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def argmax(x_pred):\n",
        "  return [np.argmax(tweet, axis=1) for tweet in x_pred]\n",
        "\n",
        "def char_decoder(x_pred):\n",
        "  \"\"\"Traduit les chaînes de nombres en caractères\"\"\"\n",
        "  arr = []\n",
        "  for tweet in x_pred:\n",
        "    arr.append(''.join([chr(c) for c in tweet if c != 0]))\n",
        "  return np.array(arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN5-kvptsIKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_pred = sequence_autoencoder.predict(x_test_seq)\n",
        "x_pred = char_decoder(argmax(x_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MatJ9GUHA12Y",
        "colab_type": "code",
        "outputId": "fa2e3d15-d1d5-4134-eff7-f31661f1399c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(x_pred[1])\n",
        "print(x_t[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A dode conniniree your cimeee to be ab0e to make toast sxmeode \n",
            "\n",
            "A dude configures your homies to be able to make toast explode \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEOt0FPrr-B4",
        "colab_type": "text"
      },
      "source": [
        "Le modèle fonctionne bien, il y a des erreurs mais c'était attendu : la \"loss\" n'est pas nulle, et cette loss est due aux pertes lors du décodage car on compresse les données sur un espace de moindres dimensions lors de l'encodage puis on les décompresse sur un espace de plus grandes dimensions lors du décodage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_PyuqdLxVmy",
        "colab_type": "text"
      },
      "source": [
        "**Create adversarial model**\n",
        "\n",
        "Use the decoder architecture as a generator and create a discriminator that classifies tweets as generated or real. Write a custom training loop that performs the folowing:\n",
        "\n",
        "\n",
        "1.   Get a batch of real tweets\n",
        "2.   Generates a batch of generated tweets\n",
        "3.   Train the discriminator to classify real/generated using the union of both batch\n",
        "4.   Train the generator (discriminator is not trainable) to classify generated tweets as real\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNitvAyjA5xL",
        "colab_type": "code",
        "outputId": "686a8e20-b606-4e14-b64b-f02a1e563aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "inter_encoder = Sequential()\n",
        "inter_encoder.add(sequence_autoencoder.layers[0])\n",
        "inter_encoder.compile(optimizer='adadelta', loss='categorical_crossentropy')\n",
        "inter_encoder.set_weights(sequence_autoencoder.get_weights())\n",
        "inter_encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model (Model)                (None, 280)               26552     \n",
            "=================================================================\n",
            "Total params: 26,552\n",
            "Trainable params: 26,552\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu3deF8xAcxA",
        "colab_type": "code",
        "outputId": "2ab892b3-93b3-4a88-fbf8-fa92646ed64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction = inter_encoder.predict(x_test_seq)\n",
        "prediction.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96, 280)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_yQ3-6G8dX0",
        "colab_type": "code",
        "outputId": "c83c0c15-76df-452a-c228-dd145e3761d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "\n",
        "lower, upper = np.min(prediction), np.max(prediction)\n",
        "mu = np.mean(prediction)\n",
        "sigma = np.std(prediction)\n",
        "print(mu, sigma)\n",
        "print(lower, upper)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6501276 1.781072\n",
            "0.0 8.196584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65ncAXuAovVf",
        "colab_type": "code",
        "outputId": "845557a0-4d85-4dd8-8eb4-ba78ce3e96a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "sns.distplot(prediction[2], hist = False, kde = True, rug = True,\n",
        "             color = 'darkblue', \n",
        "             kde_kws={'linewidth': 3},\n",
        "             rug_kws={'color': 'black'})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4b3193c7979a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sns.distplot(prediction[2], hist = False, kde = True, rug = True,\n\u001b[0m\u001b[1;32m      2\u001b[0m              \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'darkblue'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m              \u001b[0mkde_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'linewidth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m              rug_kws={'color': 'black'})\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1hf1fUTpmD5",
        "colab_type": "code",
        "outputId": "46915dbc-f761-4e6b-8756-3a11b9cedab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "# On simule un tweet par une distribution gaussienne tronquée au min et max de \n",
        "# la distribution réelle pour garder une densité de probabilité cohérente\n",
        "\n",
        "enct = stats.truncnorm((lower - mu) / sigma,\n",
        "                           (upper - mu) / sigma,\n",
        "                           loc=mu,\n",
        "                           scale=sigma)\n",
        "genpred = np.array([enct.rvs(280) for _ in range(100)]) # 100 tweets\n",
        "sns.distplot(genpred[25], hist = False, kde = True, rug = True,\n",
        "             color = 'darkblue', \n",
        "             kde_kws={'linewidth': 3},\n",
        "             rug_kws={'color': 'black'})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc14d8afc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqR3gVgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc14f30b9b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73MFh1qpsPPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inter_decoder = Model(inputs=decoder_inputs, outputs=decoded)\n",
        "inter_decoder.set_weights(sequence_autoencoder.layers[1].get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MMLOfCjqgTv",
        "colab_type": "code",
        "outputId": "160f25e2-4801-4b1b-ca8f-ffa1834e764d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "generated_tweets = inter_decoder.predict(genpred)\n",
        "generated_tweets = char_decoder(argmax(generated_tweets))\n",
        "print(generated_tweets[50])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ntt _uho topus 20 ? tgoddfoom thhhoh Mo?'hebbacf. fotf/?t&mbb;t ohom. hh ofoopfeeplr. gh hhll Toll thobw. y borr.&o hob thocomKono_@*sttst\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PfZbuP9XVW9",
        "colab_type": "text"
      },
      "source": [
        "On doit pouvoir obtenir mieux que ça en utilisant le décodeur, ça ne doit pas être la bonne manière de faire ?\n",
        "Reste à écrire l'adversarial network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwL-j5Eu58Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}